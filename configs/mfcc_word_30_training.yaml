# MFCC 전용 30개 단어 학습 설정
# CNN + Transformer 아키텍처 사용

# 기본 설정
base_config: "configs/word_training.yaml"

# 모델 설정
model:
  type: "mfcc_transformer"  # MFCC 전용 모델
  vocab_size: 150  # 어휘 크기
  hidden_dim: 256  # 은닉층 차원
  num_layers: 4    # Transformer 레이어 수
  num_heads: 8     # 어텐션 헤드 수
  dropout: 0.1     # 드롭아웃 비율

# 데이터 설정
data:
  # 오디오 특징 설정
  audio:
    sample_rate: 16000
    min_duration: 1.0  # 최소 길이 (초)
    max_duration: 3.0  # 최대 길이 (초)
    
    # MFCC 설정
    mfcc:
      n_mfcc: 13        # MFCC 계수 수
      n_fft: 2048       # FFT 윈도우 크기
      hop_length: 64    # 프레임 간격
      win_length: 1024  # 윈도우 길이
      
    # 특징 정규화
    normalize: true
    mean_normalization: true
    variance_normalization: true
  
  # 데이터 경로
  manifest_path: "data/manifest_ipa_word_30_train.json"
  val_manifest_path: "data/manifest_ipa_word_30_val.json"
  
  # 데이터 증강
  augmentation:
    enabled: true
    noise_level: 0.01
    time_shift: 0.03
    pitch_shift: 0.03
    speed_change: 0.05
    volume_change: 0.05

# 학습 설정
training:
  # MFCC 학습에 최적화된 설정
  batch_size: 16  # MFCC 모델은 더 작은 배치로 안정적
  learning_rate: 1e-4  # MFCC 학습에 적합한 학습률
  weight_decay: 0.01
  
  # 에포크 설정
  max_epochs: 200  # MFCC 모델은 더 적은 에포크로 충분
  early_stopping_patience: 10
  
  # 스케줄러
  scheduler: "cosine"
  warmup_steps: 500  # MFCC 모델은 더 짧은 워밍업
  max_steps: 100000
  
  # 체크포인트
  save_steps: 500
  eval_steps: 500
  logging_steps: 100
  
  # 그래디언트 클리핑
  max_grad_norm: 1.0  # MFCC 모델은 더 관대한 클리핑
  
  # 혼합 정밀도
  fp16: false  # MFCC 모델은 FP16 불필요

# 평가 설정
evaluation:
  # MFCC 수준 평가 메트릭
  metrics:
    - "word_error_rate"
    - "phoneme_error_rate"
    - "character_error_rate"
    - "word_accuracy"
    - "ipa_accuracy"
  
  # 평가 주기
  eval_strategy: "steps"
  eval_steps: 500
  
  # 모델 저장
  save_strategy: "steps"
  save_steps: 500

# 출력 설정
output:
  # 모델 저장 경로
  model_dir: "models/mfcc_word_30_model"
  
  # 로그 및 체크포인트
  logging_dir: "runs/mfcc_word_30_training"
  
  # 최종 모델
  final_model_path: "models/mfcc_word_30_model_final"
  
  # 추론 결과
  inference_output: "outputs/mfcc_word_30_inference"

# IPA 변환 설정
ipa:
  # 한국어 IPA 변환 활성화
  enabled: true
  
  # 후처리 규칙 적용
  apply_post_rules: true
  
  # 강세 표시
  stress_marking: false
  
  # IPA 학습 방식
  training_approach: "direct_ipa"  # 음성 → IPA 직접 학습

# 강제 정렬 설정
alignment:
  # IPA 수준 정렬
  enabled: true
  
  # 정렬 모델 경로
  model_path: "models/mfcc_alignment_model.pth"
  
  # 정렬 파라미터
  window_size: 0.015
  hop_size: 0.003
  min_silence_duration: 0.03

# MLflow 설정
mlflow:
  enabled: true
  tracking_uri: "file:./mlruns"

# 시드 설정
seed: 42

# 디버깅 설정
debug:
  verbose: true
  save_intermediate: true
  log_gradients: false

# 단어 추적 설정
word_tracking:
  enabled: true
  target_words:
    - "바지"
    - "가방"
    - "접시"
    - "장갑"
    - "뽀뽀"
    - "포크"
    - "아프다"
    - "단추"
    - "침대"
    - "숟가락"
    - "꽃"
    - "딸기"
    - "목도리"
    - "토끼"
    - "코"
    - "짹짹"
    - "사탕"
    - "우산"
    - "싸우다"
    - "눈사람"
    - "휴지"
    - "비행기"
    - "먹다"
    - "라면"
    - "나무"
    - "그네"
    - "양말"
    - "머리"
    - "나비"
    - "웃다" 