# IPA 기반 30개 단어 학습을 위한 설정 파일
_base: word_30_training.yaml

# 데이터 설정
data:
  # IPA 기반 데이터 경로
  train_manifest: "data/manifest_ipa_word_30_train.json"
  val_manifest: "data/manifest_ipa_word_30_val.json"
  
  # IPA 어휘 파일 (자동 생성)
  vocabulary_file: "data/ipa_vocabulary.txt"
  
  # 오디오 설정
  sample_rate: 16000
  max_duration: 3.0  # 단어는 보통 1-3초
  min_duration: 1.0  # 최소 1.0초 (Wav2Vec2 요구사항 충족)
  
  # 특징 추출 설정 (IPA 학습에 최적화)
  feature_type: "mfcc"
  n_mfcc: 13
  n_fft: 2048  # 더 큰 FFT로 더 많은 프레임 생성
  hop_length: 64   # 매우 세밀한 시간 해상도 (더 많은 프레임 생성)

# 모델 설정
model:
  type: "wav2vec2"  # IPA 학습에 Wav2Vec2가 효과적
  pretrained_model: "facebook/wav2vec2-base"
  
  # IPA 학습에 최적화된 설정
  hidden_size: 768
  num_hidden_layers: 6  # 단어는 간단해서 레이어 줄임
  num_attention_heads: 12
  
  # IPA 어휘 크기 (음소 + 특수 토큰)
  vocab_size: 150  # 100개 음소 + 50개 특수 토큰
  
  # 드롭아웃 (과적합 방지)
  dropout: 0.2
  attention_dropout: 0.2

# 학습 설정
training:
  # IPA 학습에 적합한 설정
  batch_size: 16  # 작은 배치로 안정적 학습
  learning_rate: 3e-5  # IPA 학습은 더 작은 학습률
  weight_decay: 0.01
  
  # 에포크 설정
  max_epochs: 300  # IPA 학습은 더 많은 에포크 필요
  early_stopping_patience: 15  # 더 오래 기다림
  
  # 스케줄러
  scheduler: "cosine"
  warmup_steps: 1000  # IPA 학습은 더 긴 워밍업
  max_steps: 150000
  
  # 체크포인트
  save_steps: 500
  eval_steps: 500
  logging_steps: 100
  
  # 그래디언트 클리핑
  max_grad_norm: 0.3  # IPA 학습은 더 엄격한 클리핑
  
  # 혼합 정밀도
  fp16: true
  
  # 데이터 증강 (IPA 학습에 중요)
  data_augmentation:
    enabled: true
    noise_level: 0.01  # IPA 학습은 더 적은 노이즈
    time_shift: 0.03   # 작은 시간 이동
    pitch_shift: 0.03  # 작은 피치 변화
    speed_change: 0.05  # 작은 속도 변화
    volume_change: 0.05 # 작은 볼륨 변화

# 평가 설정
evaluation:
  # IPA 수준 평가 메트릭
  metrics:
    - "word_error_rate"
    - "phoneme_error_rate"
    - "character_error_rate"
    - "word_accuracy"
    - "ipa_accuracy"  # IPA 정확도
  
  # 평가 주기
  eval_strategy: "steps"
  eval_steps: 500
  
  # 모델 저장
  save_strategy: "steps"
  save_steps: 500

# 출력 설정
output:
  # 모델 저장 경로
  model_dir: "models/ipa_word_30_model"
  
  # 로그 및 체크포인트
  logging_dir: "runs/ipa_word_30_training"
  
  # 최종 모델
  final_model_path: "models/ipa_word_30_model_final"
  
  # 추론 결과
  inference_output: "outputs/ipa_word_30_inference"

# IPA 변환 설정
ipa:
  # 한국어 IPA 변환 활성화
  enabled: true
  
  # 후처리 규칙 적용
  apply_post_rules: true
  
  # 강세 표시
  stress_marking: false
  
  # IPA 학습 방식
  training_approach: "direct_ipa"  # 음성 → IPA 직접 학습

# 강제 정렬 설정
alignment:
  # IPA 수준 정렬
  enabled: true
  
  # 정렬 모델 경로
  model_path: "models/ipa_alignment_model.pth"
  
  # 정렬 파라미터 (IPA에 최적화)
  window_size: 0.015  # 더 작은 윈도우
  hop_size: 0.003     # 더 세밀한 해상도
  min_silence_duration: 0.03  # IPA 간 짧은 침묵

# MLflow 설정
mlflow:
  enabled: true
  tracking_uri: "file:./mlruns"
  experiment_name: "ipa_word_30_training"
  
# 시드 설정
seed: 42

# 디버깅 설정
debug:
  # 상세 로깅
  verbose: true
  
  # 그래디언트 체크
  gradient_checking: false
  
  # 메모리 프로파일링
  memory_profiling: false

# 단어별 성능 추적
word_tracking:
  enabled: true
  # 30개 단어별 개별 성능 추적
  target_words: [
    "바지", "가방", "접시", "장갑", "뽀뽀", "포크", "아프다", "단추", "침대", "숟가락",
    "꽃", "딸기", "목도리", "토끼", "코", "짹짹", "사탕", "우산", "싸우다", "눈사람",
    "휴지", "비행기", "먹다", "라면", "나무", "그네", "양말", "머리", "나비", "웃다"
  ]

# IPA 학습 특화 설정
ipa_training:
  # IPA 어휘 생성
  generate_ipa_vocab: true
  
  # IPA 후처리 규칙
  post_processing_rules:
    - "consonant_assimilation"
    - "vowel_harmony"
    - "syllable_boundary"
  
  # IPA 검증
  validate_ipa_output: true
  
  # IPA → 텍스트 역변환
  enable_reverse_conversion: true 